{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## About Dataset\n### LGG Segmentation Dataset\nDataset used in:\n\nMateusz Buda, AshirbaniSaha, Maciej A. Mazurowski \"Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm.\" Computers in Biology and Medicine, 2019.\n\nand\n\nMaciej A. Mazurowski, Kal Clark, Nicholas M. Czarnek, Parisa Shamsesfandabadi, Katherine B. Peters, Ashirbani Saha \"Radiogenomics of lower-grade glioma: algorithmically-assessed tumor shape is associated with tumor genomic subtypes and patient outcomes in a multi-institutional study with The Cancer Genome Atlas data.\" Journal of Neuro-Oncology, 2017.\n\nThis dataset contains brain MR images together with manual FLAIR abnormality segmentation masks.\nThe images were obtained from The Cancer Imaging Archive (TCIA).\nThey correspond to 110 patients included in The Cancer Genome Atlas (TCGA) lower-grade glioma collection with at least fluid-attenuated inversion recovery (FLAIR) sequence and genomic cluster data available.\nTumor genomic clusters and patient data is provided in `data.csv` file.","metadata":{"_uuid":"979add73-9d2e-464e-bb0a-276b072430b6","_cell_guid":"6aeee95d-42a9-4d4e-a3c5-05cdc15e5f86","execution":{"iopub.status.busy":"2022-12-22T05:53:18.539482Z","iopub.execute_input":"2022-12-22T05:53:18.540791Z","iopub.status.idle":"2022-12-22T05:53:25.150294Z","shell.execute_reply.started":"2022-12-22T05:53:18.540720Z","shell.execute_reply":"2022-12-22T05:53:25.149076Z"},"jupyter":{"outputs_hidden":true},"trusted":true}},{"cell_type":"markdown","source":"## Import packages","metadata":{"_uuid":"98cd3924-0231-467e-993c-2e0577b29c2f","_cell_guid":"6bb77c3a-880e-473b-b05d-49d41b0eba47","trusted":true}},{"cell_type":"code","source":"import os\n# https://stackoverflow.com/questions/72740907/tensorflow-cant-apply-sharing-policy-file-when-using-mirrored-strategy\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # this MUST come before any tf call.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport glob\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose, MaxPooling2D, \n                                     Dropout, Activation, BatchNormalization, concatenate)\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow_addons as tfa","metadata":{"_uuid":"d759b54c-fa62-4fee-9c47-7af784be9826","_cell_guid":"771ace3c-1006-4116-918e-9a91d6c0cf01","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:01.101724Z","iopub.execute_input":"2022-12-23T02:49:01.103184Z","iopub.status.idle":"2022-12-23T02:49:07.560356Z","shell.execute_reply.started":"2022-12-23T02:49:01.103045Z","shell.execute_reply":"2022-12-23T02:49:07.559339Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{"_uuid":"53650533-9a12-4d2b-aa42-d04e0336383a","_cell_guid":"c27d5a5e-fef2-4d43-964a-c952e948a085","trusted":true}},{"cell_type":"markdown","source":"### Get original image and mask image paths","metadata":{"_uuid":"af4f9273-218b-4932-81c0-4b49e9719a20","_cell_guid":"240555d9-84b6-4f98-bf58-87efaef7308c","trusted":true}},{"cell_type":"code","source":"imgs, masks = [], []\nfor dirname, _, filenames in os.walk(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m\"):\n    for filename in filenames:\n        if 'mask'in filename:\n            masks.append(os.path.join(dirname, filename))\n            imgs.append(os.path.join(dirname, filename.replace('_mask', '')))\n\nprint(masks[:3])\nprint(imgs[:3])","metadata":{"_uuid":"c51a3826-122f-444c-90bd-63dea531521d","_cell_guid":"df6da14c-558a-48bb-b53f-b3a3f5c44ed7","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:07.562480Z","iopub.execute_input":"2022-12-23T02:49:07.563176Z","iopub.status.idle":"2022-12-23T02:49:08.548061Z","shell.execute_reply.started":"2022-12-23T02:49:07.563126Z","shell.execute_reply":"2022-12-23T02:49:08.547088Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a dataframe","metadata":{"_uuid":"f00824db-8b62-4217-b88d-b8a95b74af53","_cell_guid":"6bd74e3d-d00f-4f95-835f-4cf040e86e62","trusted":true}},{"cell_type":"code","source":"df = pd.DataFrame({\"img_path\": imgs, \"mask_path\": masks})\ndef positiv_negativ_diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    return 1 if value > 0 else 0\n\ndf[\"diagnosis\"] = df[\"mask_path\"].map(positiv_negativ_diagnosis)","metadata":{"_uuid":"878f8c6b-d96e-439b-9eb7-6e7029075e7c","_cell_guid":"0262d65a-673e-48cd-9286-ffb6d40a5855","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:08.549732Z","iopub.execute_input":"2022-12-23T02:49:08.550425Z","iopub.status.idle":"2022-12-23T02:49:32.795890Z","shell.execute_reply.started":"2022-12-23T02:49:08.550385Z","shell.execute_reply":"2022-12-23T02:49:32.794690Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if there is a corresponding image in the same row\nprint(df.iloc[50].img_path)\nprint(df.iloc[50].mask_path)\n# Number of images with low-grade gliomas\nprint(df[\"diagnosis\"].value_counts())\ndf.head()","metadata":{"_uuid":"84290ab2-9094-44ba-b016-74c50575852c","_cell_guid":"4a6aade5-8ca9-4388-86aa-1d34d9eda6ac","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:32.798773Z","iopub.execute_input":"2022-12-23T02:49:32.799240Z","iopub.status.idle":"2022-12-23T02:49:32.822127Z","shell.execute_reply.started":"2022-12-23T02:49:32.799187Z","shell.execute_reply":"2022-12-23T02:49:32.820978Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check image shape","metadata":{"_uuid":"71a81341-850b-4a9c-ac7c-996813b32b17","_cell_guid":"a1cdd1d3-8948-482d-a1bd-af85e2f2a588","trusted":true}},{"cell_type":"code","source":"def print_img_shape_randomly_chosen(df, n=10):\n    print(\"\\t\\t\\t   Image Shape\\t\\t\\t  Mask Shape\")\n    for row in df.sample(n).itertuples():\n        print(\n            f\"Randomly Chosen Index {row.Index}: \"\n            + f\"{get_img_shape(row.img_path)}\\t\\t\"\n            + f\"{get_img_shape(row.mask_path)}\\n\"\n        )\n\ndef get_img_shape(img_path):\n    img = cv2.imread(img_path)\n    return img.shape\n\nprint_img_shape_randomly_chosen(df)","metadata":{"_uuid":"45b1d850-333e-4c32-8f8d-f53bebc2059c","_cell_guid":"5ec08c80-afd5-4fdc-9df6-68cf290e0981","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:32.823778Z","iopub.execute_input":"2022-12-23T02:49:32.824463Z","iopub.status.idle":"2022-12-23T02:49:32.945384Z","shell.execute_reply.started":"2022-12-23T02:49:32.824427Z","shell.execute_reply":"2022-12-23T02:49:32.944408Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize images","metadata":{"_uuid":"d335749b-f69d-4ebd-bbb5-b7f5e7b606eb","_cell_guid":"bd51648c-29c9-47c1-a084-91a5659a19e1","trusted":true}},{"cell_type":"code","source":"def show_image_randomly_chosen(df, n=5):\n    fig, axs = plt.subplots(n, 3, figsize=[15, 15])\n    axs[0, 0].set_title(\"Brain MRI Slice\")\n    axs[0, 1].set_title('Mask')\n    axs[0, 2].set_title('Brain MRI Slice with Mask')\n    for i, row in enumerate(df.sample(n).itertuples()):\n        img = cv2.imread(row.img_path)\n        mask = cv2.imread(row.mask_path)\n        \n        axs[i, 0].imshow(img)\n        \n        axs[i, 1].imshow(mask)\n        \n        axs[i, 2].imshow(img)\n        axs[i, 2].imshow(mask, alpha=0.3)\n        \n        axs[i, 2].grid(True)\n    plt.show()\n\nshow_image_randomly_chosen(df, n=3)","metadata":{"_uuid":"1505feb8-2a0e-490c-a9cf-7dadf5ed9cce","_cell_guid":"334913a4-5ce9-42b8-850e-723c80adebbc","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:32.946852Z","iopub.execute_input":"2022-12-23T02:49:32.947384Z","iopub.status.idle":"2022-12-23T02:49:34.321031Z","shell.execute_reply.started":"2022-12-23T02:49:32.947349Z","shell.execute_reply":"2022-12-23T02:49:34.319931Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking a (random) image","metadata":{"_uuid":"dbe0e594-f194-4ec3-829a-8e40fa273fa2","_cell_guid":"0e9cd78f-f9a7-4e9c-8f7a-918c058c8638","trusted":true}},{"cell_type":"code","source":"def check_img(df, idx=None):\n    if idx is None:\n        idx = df.sample().index[0]\n    \n    img_ck = cv2.imread(df.img_path[idx])\n    msk_ck = cv2.imread(df.mask_path[idx])\n    img_ck = cv2.cvtColor(img_ck, cv2.COLOR_BGR2RGB)\n    img_ck = img_ck / 255\n    msk_ck = msk_ck / 255\n    \n    fig, axs = plt.subplots(1, 2, figsize=[12, 15])\n    axs[0].imshow(img_ck)\n    axs[0].set_title(f\"maximum and minimum pixel values: {img_ck.max()}, {img_ck.min()}\")\n\n    axs[1].imshow(msk_ck, cmap=\"gray\", alpha=.1)\n    axs[1].set_title(f\"maximum and minimum pixel values: {msk_ck.max()}, {msk_ck.min()}\")\n    plt.show()\ncheck_img(df, idx=2)","metadata":{"_uuid":"0fa45d78-42d7-458d-a047-0fba186b62c0","_cell_guid":"a8fa8a7b-b4d5-4bf7-a1f1-3f5e3ce53a5a","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:34.322011Z","iopub.execute_input":"2022-12-23T02:49:34.322328Z","iopub.status.idle":"2022-12-23T02:49:34.767358Z","shell.execute_reply.started":"2022-12-23T02:49:34.322299Z","shell.execute_reply":"2022-12-23T02:49:34.765468Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define data generators for training data set, validation data set and test data set","metadata":{"_uuid":"f402db60-272d-44d1-9756-fac667285317","_cell_guid":"c424809b-6b3e-4d63-b278-420cd9329bd5","trusted":true}},{"cell_type":"markdown","source":"### Split the data (path of images) into training data set, validation data set and test data set","metadata":{"_uuid":"18d725bb-3b46-4b3a-89f7-7b60d9665023","_cell_guid":"e11be8e7-ff1b-43b6-98f8-e144ac8e4147","trusted":true}},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.1, random_state=2, shuffle=True)\ndf_train, df_val = train_test_split(df_train, test_size=0.1, random_state=42, shuffle=True)\nprint(\"Shape of training data set: \", df_train.shape)\nprint(\"Shape of validation data set: \", df_val.shape)\nprint(\"Shape of test data set: \", df_test.shape)","metadata":{"_uuid":"76f5d036-69bc-412e-a216-ef0622a6e0f9","_cell_guid":"b0b13a25-aa3b-4bb3-a915-caa0c6a3feb3","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:34.769060Z","iopub.execute_input":"2022-12-23T02:49:34.770026Z","iopub.status.idle":"2022-12-23T02:49:34.782222Z","shell.execute_reply.started":"2022-12-23T02:49:34.769987Z","shell.execute_reply":"2022-12-23T02:49:34.780878Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image data generator and data augmentation","metadata":{"_uuid":"7f972d4c-0469-4300-81ee-609c6637d4af","_cell_guid":"fdeb702f-15ef-43a8-994f-c632120ffe31","trusted":true}},{"cell_type":"markdown","source":"### Config","metadata":{"_uuid":"1a9c66f1-8bda-43dd-934d-fb95b5cab578","_cell_guid":"6d4aa784-38aa-45b1-89fa-5aa051ba5f88","trusted":true}},{"cell_type":"code","source":"batch_size = 32\nimg_height = 256\nimg_width = 256\n\naugmentation_dict = dict(\n    rotation_range=0.1,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    brightness_range=(0.2,1.3),\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode=\"nearest\",\n)","metadata":{"_uuid":"328ef0ca-dd95-4bee-892e-2c2acc87bc05","_cell_guid":"159e150f-5791-44a1-951e-c7b983eea2c3","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:34.783863Z","iopub.execute_input":"2022-12-23T02:49:34.784449Z","iopub.status.idle":"2022-12-23T02:49:34.791289Z","shell.execute_reply.started":"2022-12-23T02:49:34.784414Z","shell.execute_reply":"2022-12-23T02:49:34.789896Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define data generator function","metadata":{"_uuid":"68e0b430-8dc9-4f80-a956-e026d7051272","_cell_guid":"b5dd7b9c-4e7c-458f-bac9-2a24d06c2b59","execution":{"iopub.status.busy":"2022-12-22T10:11:56.991447Z","iopub.execute_input":"2022-12-22T10:11:56.991952Z","iopub.status.idle":"2022-12-22T10:11:56.997374Z","shell.execute_reply.started":"2022-12-22T10:11:56.991912Z","shell.execute_reply":"2022-12-22T10:11:56.996203Z"},"trusted":true}},{"cell_type":"code","source":"def make_data_generator(\n    dataframe,\n    batch_size,\n    augmentation_dict,\n    target_size=(img_height, img_width),\n    image_x_col=\"img_path\",\n    mask_x_col=\"mask_path\",\n    image_color_mode=\"rgb\",\n    mask_color_mode=\"grayscale\",\n    image_save_prefix=\"image\",\n    mask_save_prefix=\"mask\",\n    save_to_dir=None,\n    seed=2\n):\n    \n    # ImageDataGenerator generate batches of tensor image data with real-time data augmentation.\n    _image_data_generator = ImageDataGenerator(**augmentation_dict)\n    _mask_data_generator = ImageDataGenerator(**augmentation_dict)\n    \n    image_data_generator = _image_data_generator.flow_from_dataframe(\n        dataframe=dataframe,\n        x_col=image_x_col,\n        target_size=target_size,\n        color_mode=image_color_mode,\n        class_mode=None,  # modes for yielding the target, None means no targets returned\n        batch_size=batch_size,\n        seed=seed,\n        save_to_dir=save_to_dir,\n        save_prefix=image_save_prefix\n    )\n    mask_data_generator = _mask_data_generator.flow_from_dataframe(\n        dataframe=dataframe,\n        x_col=mask_x_col,\n        target_size=target_size,\n        color_mode=mask_color_mode,\n        class_mode=None,\n        batch_size=batch_size,\n        seed=seed,\n        save_to_dir=save_to_dir,\n        save_prefix=mask_save_prefix\n    )\n    \n    for (img, mask) in zip(image_data_generator, mask_data_generator):\n        img, mask = normalise_and_set_threshold(img, mask)\n        yield (img, mask)\n\ndef normalise_and_set_threshold(image, mask):\n    image = image/255\n    mask = mask/255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    return (image, mask)","metadata":{"_uuid":"ba745ce7-1945-49f6-b34b-14385bb92b97","_cell_guid":"eb543dae-11ad-4e44-9b08-090689f79aee","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:34.795814Z","iopub.execute_input":"2022-12-23T02:49:34.796606Z","iopub.status.idle":"2022-12-23T02:49:34.809062Z","shell.execute_reply.started":"2022-12-23T02:49:34.796578Z","shell.execute_reply":"2022-12-23T02:49:34.807469Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get data generator","metadata":{"_uuid":"bb519f5d-04a9-4ff4-8af4-e87d313e10e2","_cell_guid":"2ae870f4-d2ee-4970-ba41-461ce41c9f90","trusted":true}},{"cell_type":"code","source":"train_data_generator = make_data_generator(\n    df_train,\n    batch_size,\n    augmentation_dict,\n    target_size=(img_height, img_width)\n)\nval_data_generator = make_data_generator(\n    df_val,\n    batch_size,\n    dict(),\n    target_size=(img_height, img_width)\n)\ntest_data_generator = make_data_generator(\n    dataframe=df_test,\n    batch_size=batch_size,\n    augmentation_dict=dict(),\n    target_size=(img_height, img_width)\n)","metadata":{"_uuid":"5067a4a1-43b1-4e7f-a649-a961704627b5","_cell_guid":"95d86dfc-ffc2-4ad9-8427-c284754a670b","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T02:49:34.810932Z","iopub.execute_input":"2022-12-23T02:49:34.811628Z","iopub.status.idle":"2022-12-23T02:49:34.820549Z","shell.execute_reply.started":"2022-12-23T02:49:34.811589Z","shell.execute_reply":"2022-12-23T02:49:34.819302Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Losses and metrics","metadata":{"_uuid":"c80ef0fa-7f4f-442e-b59b-820d89fbf5c3","_cell_guid":"988828f2-0d2d-49d7-aeac-89d0403a7b2e","trusted":true}},{"cell_type":"code","source":"def iou(y_true, y_pred, smooth=K.epsilon()):\n    \"\"\"\n    Intersection over Union (IoU) or Jaccard index (Jaccard similarity coefficient)\n    for segmentation maps.\n    \n        TP / (TP + FP + FN)\n    \"\"\"\n    intersection = K.sum(y_true * y_pred)  # TP\n    union = K.sum(y_true) + K.sum(y_pred) - intersection  # (TP + FN) + (TP + FP) - TP\n    return (intersection + smooth) / (union + smooth)\n   \ndef iou_loss(y_true, y_pred, smooth=K.epsilon()):\n    return 1 - iou(y_true, y_pred, smooth=smooth)\n\ndef dice_coef(y_true, y_pred, smooth=K.epsilon()):\n    \"\"\"\n    Sørensen–Dice coefficient\n    \n        2 * TP / (2 * TP + FP + FN)\n    \"\"\"\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)  # TP\n    y_true_area = K.sum(y_true)  # TP + FN\n    y_pred_area = K.sum(y_pred)  # TP + FP\n    combined_area = y_true_area + y_pred_area  # 2 * TP + FP + FN\n    return (2 * intersection + smooth) / (combined_area + smooth)\n\ndef dice_loss(y_true, y_pred, smooth=K.epsilon()):\n    return 1 - dice_coef(y_true, y_pred, smooth=smooth)","metadata":{"_uuid":"8c8e8659-29b1-422e-8b85-b28c8042dd94","_cell_guid":"1d31a662-a4e5-4746-bc3e-8245227ab777","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2022-12-23T02:49:34.822747Z","iopub.execute_input":"2022-12-23T02:49:34.823743Z","iopub.status.idle":"2022-12-23T02:49:34.834422Z","shell.execute_reply.started":"2022-12-23T02:49:34.823708Z","shell.execute_reply":"2022-12-23T02:49:34.833346Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define model","metadata":{"_uuid":"b4f8d16d-b075-4e68-86a8-114c1625dd6f","_cell_guid":"e2e26875-4a38-4807-be66-286bdd5e3b1c","trusted":true}},{"cell_type":"markdown","source":"### Unet","metadata":{"_uuid":"d7381ad5-d0ca-449c-9ac9-ac3ef3586fda","_cell_guid":"42183239-4fea-46dd-b690-ef1cf892ad79","trusted":true}},{"cell_type":"code","source":"def conv2d_block(\n    tensor,\n    num_filters,\n    kernel_size=(3, 3),\n    stack_num=2,\n    batch_norm=True,\n    activation_func=\"relu\"\n):\n    \"\"\"https://github.com/yingkaisha/keras-unet-collection/blob/d30f14a259656d2f26ea11ed978255d6a7d0ce37/keras_unet_collection/layer_utils.py#L197\"\"\"\n    bias_flag = not batch_norm\n    \n    for i in range(stack_num):\n        # linear convolution\n        tensor = Conv2D(\n            filters=num_filters,\n            kernel_size=kernel_size,\n            use_bias=bias_flag,\n            kernel_initializer=\"he_normal\",\n            padding=\"same\")(tensor)\n        # batch normalization\n        if batch_norm:\n            tensor = BatchNormalization(axis=3)(tensor)\n        # activation\n        tensor = Activation(activation_func)(tensor)\n    return tensor\n\ndef encoder_block(input_tensor, num_filters, dropout_rate=0.1):\n    tensor4concat = conv2d_block(input_tensor, num_filters)\n    tensor_pooling = MaxPooling2D(pool_size=(2, 2))(tensor4concat)\n    tensor_pooling = Dropout(dropout_rate)(tensor_pooling)\n    return tensor4concat, tensor_pooling\n\ndef decoder_block(input_tensor, filters, concat_layer, dropout_rate=0.1):\n    x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding=\"same\")(input_tensor)\n    x = concatenate([x, concat_layer], axis=-1)\n    x = Dropout(dropout_rate)(x)\n    x = conv2d_block(x, filters)\n    return x\n\ndef unet(img_shape=(img_height, img_width, 3), num_class=1):\n    \"\"\"\n    Parameters\n    ----------\n    img_shape : tuple\n        Shape of the image.\n    num_class : int\n        Output class number.\n    \n    Returns\n    -------\n      model : keras.engine.functional.Functional\n          UNet model.\n    \"\"\"\n    input_img = Input(shape=img_shape, name='main_input')\n    conv1_1, pool1 = encoder_block(input_img, 64)\n    conv2_1, pool2 = encoder_block(pool1, 128)\n    conv3_1, pool3 = encoder_block(pool2, 256)\n    conv4_1, pool4 = encoder_block(pool3, 512)\n    conv5_1 = conv2d_block(pool4, 1024)\n    conv4_2 = decoder_block(conv5_1, 512, conv4_1)\n    conv3_3 = decoder_block(conv4_2, 256, conv3_1)\n    conv2_4  = decoder_block(conv3_3, 128, conv2_1)\n    conv1_5 = decoder_block(conv2_4, 64, conv1_1)\n    unet_output = Conv2D(\n        num_class, (1, 1),\n        activation='sigmoid',\n        padding='same',\n        kernel_initializer='he_normal',\n        kernel_regularizer=l2(3e-4),\n        name='output'\n    )(conv1_5)\n    model = Model(inputs=[input_img, ], outputs=[unet_output, ], name=\"Unet\")\n    return model","metadata":{"_uuid":"ba40af81-2f2c-484c-a4e1-4dcb718698db","_cell_guid":"b3060503-9233-41f0-a458-88fadcd06aa2","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T03:06:27.724891Z","iopub.execute_input":"2022-12-23T03:06:27.725291Z","iopub.status.idle":"2022-12-23T03:06:27.742726Z","shell.execute_reply.started":"2022-12-23T03:06:27.725254Z","shell.execute_reply":"2022-12-23T03:06:27.741493Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Optimizer and Callbacks","metadata":{"_uuid":"73f283fb-5ca9-4e27-b9c7-bffd32c64ed8","_cell_guid":"cceb295f-0a75-4012-a34b-78600643fb1c","trusted":true}},{"cell_type":"code","source":"steps_per_epoch = len(df_train) // batch_size\nval_steps = len(df_val) / batch_size\n\nclr = tfa.optimizers.CyclicalLearningRate(\n    initial_learning_rate=1e-4,\n    maximal_learning_rate=0.5,\n    scale_fn=lambda x: 1,\n    step_size=0.5 * steps_per_epoch\n)\noptimizer = tf.keras.optimizers.SGD(\n    learning_rate=clr,\n    momentum=0.01,\n    nesterov=False,\n    name='SGD',\n)\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=0.0001, verbose=1),\n    tf.keras.callbacks.ModelCheckpoint('mri_seg_keras_unet.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","metadata":{"_uuid":"d467fa55-5b66-4a7d-b61a-11b23c548b79","_cell_guid":"ec28dc73-0eb1-4b88-a14d-32f5a6f01d28","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T03:16:20.380444Z","iopub.execute_input":"2022-12-23T03:16:20.380807Z","iopub.status.idle":"2022-12-23T03:16:20.389870Z","shell.execute_reply.started":"2022-12-23T03:16:20.380774Z","shell.execute_reply":"2022-12-23T03:16:20.388902Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile model and training","metadata":{"_uuid":"85f006da-6e38-49b7-bf45-4d2874c903c7","_cell_guid":"c1575e4d-79ad-4985-af9a-8aec35eb572e","trusted":true}},{"cell_type":"code","source":"mirrored_strategy = tf.distribute.MirroredStrategy()\n\nwith mirrored_strategy.scope():\n    model = unet()\n# model.summary()\nmodel.compile(\n    optimizer=optimizer,\n    loss=dice_loss, \n    metrics=[\"binary_accuracy\", iou, dice_coef],\n)","metadata":{"_uuid":"d9e32273-df09-4972-903c-6dae8a38f0c5","_cell_guid":"c3bba8c3-6971-489a-ae29-f856d997fa57","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T03:16:23.405091Z","iopub.execute_input":"2022-12-23T03:16:23.405676Z","iopub.status.idle":"2022-12-23T03:16:24.169148Z","shell.execute_reply.started":"2022-12-23T03:16:23.405629Z","shell.execute_reply":"2022-12-23T03:16:24.168136Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 150\n\nhistory = model.fit(\n    train_data_generator,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    callbacks=callbacks, \n    validation_data=val_data_generator,\n    validation_steps=val_steps,\n)","metadata":{"_uuid":"3a297f03-9f7b-4ea4-93b7-d3eea016b2c9","_cell_guid":"fc4d0e18-f583-4fb4-b0ac-28c5f17f305a","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T03:16:27.328372Z","iopub.execute_input":"2022-12-23T03:16:27.328891Z","iopub.status.idle":"2022-12-23T04:14:37.590901Z","shell.execute_reply.started":"2022-12-23T03:16:27.328844Z","shell.execute_reply":"2022-12-23T04:14:37.588726Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Post training visualisation","metadata":{"_uuid":"ca181299-a664-4d69-b756-926fc41f9452","_cell_guid":"d20742b6-246b-4eac-bbb9-3e95285c89b1","trusted":true}},{"cell_type":"code","source":"history_post_training = history.history\n\ntrain_dice_coeff_list = history_post_training['dice_coef']\nval_dice_coeff_list = history_post_training['val_dice_coef']\n\ntrain_jaccard_list = history_post_training['iou']\nval_jaccard_list = history_post_training['val_iou']\n\ntrain_loss_list = history_post_training['loss']\nval_loss_list = history_post_training['val_loss']\n\nplt.figure(figsize=(8, 6))\nplt.figure(1)\nplt.plot(train_loss_list, 'b-')\nplt.plot(val_loss_list, 'r-')\n\nplt.xlabel('iterations')\nplt.ylabel('loss')\nplt.title('Loss graph', fontsize=12)\nplt.legend(['train', 'val']);\n\nplt.figure(figsize=(8, 6))\nplt.figure(2)\nplt.plot(train_dice_coeff_list, 'b-')\nplt.plot(val_dice_coeff_list, 'r-')\n\nplt.xlabel('iterations')\nplt.ylabel('accuracy')\nplt.title('Dice coefficient graph', fontsize=12)\nplt.legend(['train', 'val']);\nplt.show()","metadata":{"_uuid":"096b33b6-afac-457d-9b48-2fb9d20a259f","_cell_guid":"12ed1d51-fb22-400f-b14e-3497165bc7ec","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T04:16:45.659345Z","iopub.execute_input":"2022-12-23T04:16:45.659725Z","iopub.status.idle":"2022-12-23T04:16:46.102880Z","shell.execute_reply.started":"2022-12-23T04:16:45.659690Z","shell.execute_reply":"2022-12-23T04:16:46.101886Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load trained model","metadata":{"_uuid":"0cbf1c63-0e9c-406f-8d73-fb702522bd66","_cell_guid":"94be4eb7-4418-4107-942a-d77fe7a6b33d","trusted":true}},{"cell_type":"code","source":"model.load_weights(\"mri_seg_keras_unet.h5\")\n# We can't load the model with the following method, because we only save the weights\n# model = load_model(\n#     \"mri_seg_keras_unet.h5\",\n#     custom_objects={\n#         \"dice_loss\": dice_loss,\n#         \"iou\": iou,\n#         \"dice_coef\": dice_coef\n#     }\n# )\n\nresults = model.evaluate(test_data_generator, steps=len(df_test) / batch_size)\nprint(\"Test loss: \", results[0])\nprint(\"Test IOU: \", results[2])\nprint(\"Test Dice Coefficent: \",results[3])","metadata":{"_uuid":"ae98f659-d119-42f0-b2dc-34c265855702","_cell_guid":"9dc9873b-056d-4736-838d-98d5c79b3c43","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T04:23:30.183524Z","iopub.execute_input":"2022-12-23T04:23:30.183916Z","iopub.status.idle":"2022-12-23T04:23:39.218391Z","shell.execute_reply.started":"2022-12-23T04:23:30.183880Z","shell.execute_reply":"2022-12-23T04:23:39.217434Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show prediction on test data set","metadata":{}},{"cell_type":"code","source":"try:\n    count = 0\n    fig, axs = plt.subplots(10, 4, figsize = (20, 50), facecolor='w')\n    for i in range(10):\n      index = np.random.randint(0, len(df_test)) \n      image_path = df_test['img_path'].iloc[index]\n      mask_path = df_test['mask_path'].iloc[index]\n      image = cv2.imread(image_path)\n      mask = cv2.imread(mask_path)\n      img = cv2.resize(image, (img_height, img_width))\n      img = img/255\n      img = img[np.newaxis,:,:,:]\n      pred=model.predict(img)\n\n      axs[count][0].title.set_text('Original Image')\n      axs[count][0].imshow(np.squeeze(img))\n\n      axs[count][1].title.set_text('Original Mask')\n      axs[count][1].imshow(mask, cmap = 'gray')\n\n      axs[count][2].title.set_text('Prediction')\n      axs[count][2].imshow(np.squeeze(pred))\n\n      axs[count][3].title.set_text('Binary Prediction')\n      axs[count][3].imshow(np.squeeze(pred) > 0.5)\n      count+=1\n    fig.tight_layout()\nexcept Exception as e:\n    print(str(e))","metadata":{"_uuid":"d036327a-6efb-4a02-ae97-e7b4134ba4ec","_cell_guid":"aefa5c00-0353-4b09-b39d-b7258784324f","collapsed":false,"execution":{"iopub.status.busy":"2022-12-23T04:29:05.883428Z","iopub.execute_input":"2022-12-23T04:29:05.883797Z","iopub.status.idle":"2022-12-23T04:29:14.680693Z","shell.execute_reply.started":"2022-12-23T04:29:05.883755Z","shell.execute_reply":"2022-12-23T04:29:14.679837Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\n- [Kaggle Notebook: brain_mri_segmentation](https://www.kaggle.com/code/irfanqasim/brain-mri-segmentation/notebook)\n- [Kaggle Notebook: AttentionUNET_keras](https://www.kaggle.com/code/shahbaz92fast/attentionunet-keras)\n- [Kaggle Notebook: Final Machine Learning](https://www.kaggle.com/code/luyen0/final-machine-learning)\n- [Kaggle Notebook: Brain Tumor](https://www.kaggle.com/code/ziadhussien/brain-tumor)\n- [影像切割任務常用的指標-IoU和Dice coefficient](https://chih-sheng-huang821.medium.com/%E5%BD%B1%E5%83%8F%E5%88%87%E5%89%B2%E4%BB%BB%E5%8B%99%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8C%87%E6%A8%99-iou%E5%92%8Cdice-coefficient-3fcc1a89cd1c)\n- [GitHub: yingkaisha/keras-unet-collection](https://github.com/yingkaisha/keras-unet-collection)\n- [GitHub: JunMa11/SegLossJunMa11/SegLoss](https://github.com/JunMa11/SegLoss)\n- [An overview of semantic image segmentation.](https://www.jeremyjordan.me/semantic-segmentation/)\n- [3 Common Loss Functions for Image Segmentation](https://dev.to/_aadidev/3-common-loss-functions-for-image-segmentation-545o)","metadata":{"_uuid":"c2ef0eb5-9ae8-4399-a861-0b330a5cc4f2","_cell_guid":"84a0ff15-2550-4ef7-a77c-48c70266687f","trusted":true}}]}